# Image CLassification using CNN


# Problem
The task of this project is to develop a vision-based framework that enables users to interact with computers through human gestures. With the development of ubiquitous computing, the traditional input devices such as keyboard, mouse, and pen are not sufficient to provide a natural and efficient interaction experience. Therefore, direct use of hands as an input device can be used to overcome this limitation and expand the usable command set.

# Introduction
Human gestures have been a significant way of communication, and they could be utilized to enhance human-machine interfaces. By recognizing human gestures, users can control a wide variety of devices remotely. To achieve this goal, a vision-based framework can be developed that allows users to interact with computers through human gestures.

# Intro to CNN
Convolutional Neural Networks (CNNs) have shown remarkable performance in image classification tasks. They have been successfully applied to various problems, including object detection, image segmentation, and facial recognition. In this project, a CNN will be used to classify human gestures.

CNNs are effective in image classification because they can capture local features and their spatial relationships within an image. This is achieved by applying convolutional filters to the input image, followed by pooling layers that reduce the spatial dimensions of the feature maps while preserving their essential information.
## üî∞ Getting Started

### ‚úÖ Prerequisites: 
- [ ] [Python](https://www.python.org/downloads/)
- [ ] [Jupyter Notebook](https://jupyter.org/)
- [ ] [Webcam]()

###  üîé Features:

 - Real time detection
 - Less Memory consumption
 - Better Performance than traditional CNN

## ü§ù Contributors
[Arham](https://github.com/Arham-123366) 


Please give a rating.